# Flammie tests: ChatGPT is that one drunk dude at a bar who has the best stories

ChatGPT is a chatbot invented in early 2020's that is based on large language
models and neural network technology, some call it an artificial intelligence
and it is indeed a leap ahead of chatbots that came before it and it has
gathered much of popular interest and use through the early 2020s now. The thing
is, it produces perfectly grammatical and idiomatic English and passable other
world languages too (training data is 98 % English and some 0.1 % in many of the
top 100 languages of the world c.f. [my guesstimate of language resource
sizes]()), however, the texts it produces are not truthful or even coherent. As
it is basically a copy/paste machine of all the texts of the internet with a
somewhat clever smush function to combine clippings together (or a lossy
compression algorithm for text if you want to think it other way), it cannot
really guarantee truthiness or consequentialness of anything it produces, it's
still just snippets of texts that may or may not be relevant in some context.
The more time progresses the relevance does seem to be improving, but there are
certain underlying parts in truthfulness that cannot be overcome with current
approach with just more data and more compute.

As it happens this kind of stories conjured up from bits and pieces are highly
entertaining, and reading these stories does remind me of meeting certain
storytellers at bars, you probably all have experienced this in your life,
usually an elderly man who starts to talking with anyone at a bar and has the
most amazing stories to tell: he built the biggest boats in the world, played
guitar with Ozzy Osbourne as a touring musician, climbed Mt. Everest and so
forth, and all these stories also sound very believable and entertaining, as
long as you aren't an expert on the topic they talk about you might be tempted
to believe. The thing is you don't believe them after one too many amazing
stories, but people have started to believe in ChatGPT, making travel plans with
it, or gym programs, or learning languages or school subjects with it, but it's
always at least 10 % not true, you will have non-existent places to visit in
your travel plan, harmful advice in your gym plan, and non-facts copypasted from
the internet or hallucinated in your language learning material or school
helper. It scares me to think that so many people trust in chatGPT's stories
what kind of a generation will we have when these people grow up...

If you want to understand how bad chat gpt is, if you are an expert in anything,
it is very easy to ask questions about your expertise that likely haven't been
talked about that much in reddit, stack exchange or other things where chat gpt
sources its materials. For me it's Obviously grammars of Uralic languages, even
easy things like Finnish, I can ask a question that most Finnish speakers
without specific education in linguistics could probably answer, like how to
inflect this tricky word, what is the grammatically correct way of using some
expression and it will fail quite fast. If your expertise is pokemon cards or
1970's french progressive rock, it doesn't matter, anything that's beyond
information that is repeated weekly or monthly on social media chatgpt will
eventually reveal its lack of actual knowledge. Or one thing I like to do is,
"where should a millennial queer metalhead visiting my hometown of asswards
backwateria in West Brutopia go on a holiday there?" There's like a 100 % chance
you'll get hallucinations as a reply.
